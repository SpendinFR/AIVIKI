# Gestion de l'autonomie : auto-seed d'objectifs, micro-constitution, agenda, d√©duplication et fallback
# Compatible avec l'architecture existante (GoalSystem, Metacognition, Memory, Perception, Language, etc.)
# Aucune d√©pendance externe (stdlib uniquement). Logs lisibles dans ./logs/autonomy.log

from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple
from collections import deque, defaultdict
import os, time, uuid, json, threading, random, math

from AGI_Evolutive.utils.jsonsafe import json_sanitize

# --------- Structures ---------

@dataclass
class AgendaItem:
    id: str
    title: str
    rationale: str
    kind: str              # "learning" | "reasoning" | "intake" | "alignment" | "meta"
    priority: float        # 0..1
    created_at: float
    payload: Dict[str, Any] = field(default_factory=dict)
    status: str = "queued" # queued | running | done | skipped
    dedupe_key: Optional[str] = None

# --------- Autonomy Manager ---------

class AdaptiveEMA:
    """EMA avec choix dynamique de beta via Thompson Sampling."""

    def __init__(self,
                 betas: Tuple[float, ...] = (0.2, 0.4, 0.6, 0.8),
                 error_threshold: float = 0.05,
                 drift_threshold: float = 0.12,
                 forgetting: float = 0.975):
        self.betas = betas
        self.error_threshold = error_threshold
        self.drift_threshold = drift_threshold
        self.forgetting = forgetting
        self.state: Optional[float] = None
        self.last_smoothed: Optional[float] = None
        self.posteriors: Dict[float, Tuple[float, float]] = {
            b: [1.0, 1.0] for b in betas
        }

    def _sample_posterior(self, beta: float) -> float:
        a, b = self.posteriors[beta]
        return random.betavariate(max(a, 1e-3), max(b, 1e-3))

    def _decay_posteriors(self, beta: float) -> None:
        a, b = self.posteriors[beta]
        a = max(1.0, self.forgetting * a)
        b = max(1.0, self.forgetting * b)
        self.posteriors[beta] = [a, b]

    def update(self, value: float) -> Dict[str, float]:
        if value is None or math.isnan(value):
            return {
                "smoothed": self.state if self.state is not None else 0.0,
                "beta": self.betas[-1],
                "error": 0.0,
                "drift": 0.0,
                "error_threshold": self.error_threshold,
                "drift_threshold": self.drift_threshold,
            }

        if self.state is None:
            self.state = value
            self.last_smoothed = value
            return {
                "smoothed": value,
                "beta": self.betas[-1],
                "error": 0.0,
                "drift": 0.0,
                "error_threshold": self.error_threshold,
                "drift_threshold": self.drift_threshold,
            }

        sampled = {b: self._sample_posterior(b) for b in self.betas}
        chosen_beta = max(sampled.items(), key=lambda kv: kv[1])[0]
        self._decay_posteriors(chosen_beta)

        prev_state = self.state
        self.state = (chosen_beta * value) + ((1.0 - chosen_beta) * self.state)
        error = abs(self.state - value)
        drift = abs(self.state - (self.last_smoothed if self.last_smoothed is not None else prev_state))
        success = 1 if error <= self.error_threshold else 0
        a, b = self.posteriors[chosen_beta]
        self.posteriors[chosen_beta] = [a + success, b + (1 - success)]
        self.last_smoothed = self.state

        return {
            "smoothed": self.state,
            "beta": chosen_beta,
            "error": error,
            "drift": drift,
            "error_threshold": self.error_threshold,
            "drift_threshold": self.drift_threshold,
        }


class StreamingCorrelation:
    """Corr√©lation glissante avec facteur d'oubli."""

    def __init__(self, forgetting: float = 0.97):
        self.forgetting = forgetting
        self.mean_x = 0.0
        self.mean_y = 0.0
        self.var_x = 1e-6
        self.var_y = 1e-6
        self.cov_xy = 0.0

    def update(self, x: float, y: float) -> float:
        decay = self.forgetting
        prev_mean_x = self.mean_x
        prev_mean_y = self.mean_y
        self.mean_x = (decay * self.mean_x) + ((1 - decay) * x)
        self.mean_y = (decay * self.mean_y) + ((1 - decay) * y)
        self.cov_xy = (decay * self.cov_xy) + ((1 - decay) * (x - prev_mean_x) * (y - prev_mean_y))
        self.var_x = (decay * self.var_x) + ((1 - decay) * (x - prev_mean_x) * (x - self.mean_x))
        self.var_y = (decay * self.var_y) + ((1 - decay) * (y - prev_mean_y) * (y - self.mean_y))

        if self.var_x <= 1e-8 or self.var_y <= 1e-8:
            return 0.0
        corr = max(-1.0, min(1.0, self.cov_xy / math.sqrt(self.var_x * self.var_y)))
        return corr


class OnlineWeightLearner:
    """Mise √† jour en ligne type ridge pour pond√©rer les priorit√©s."""

    def __init__(self, l2: float = 0.1, max_step: float = 0.05, forgetting: float = 0.98):
        self.l2 = l2
        self.max_step = max_step
        self.forgetting = forgetting
        self.weights: Dict[str, float] = defaultdict(lambda: 0.8)

    def update(self, key: str, feature: float, target: float) -> float:
        if feature <= 0:
            return self.weights[key]
        weight = self.weights[key] * self.forgetting
        prediction = weight * feature
        gradient = (target - prediction) * feature - (self.l2 * weight)
        step = max(-self.max_step, min(self.max_step, gradient))
        weight = max(0.1, min(2.5, weight + step))
        self.weights[key] = weight
        return weight


class MetricLearningState:
    """Suivi des m√©triques faibles avec lissage adaptatif et poids appris."""

    def __init__(self, name: str, forgetting: float = 0.97):
        self.name = name
        self.ema = AdaptiveEMA()
        self.last_raw: Optional[float] = None
        self.forgetting = forgetting
        self.correlation = StreamingCorrelation(forgetting=forgetting)
        self.last_corr = 0.0

    def observe(self, value: float, learner: OnlineWeightLearner) -> Dict[str, float]:
        ema_state = self.ema.update(value)
        improvement = 0.0 if self.last_raw is None else value - self.last_raw
        severity = max(0.0, 1.0 - ema_state["smoothed"])
        weight = learner.update(self.name, severity, max(0.0, -improvement))
        corr = self.correlation.update(ema_state["smoothed"], max(0.0, -improvement))
        self.last_raw = value

        return {
            "metric": self.name,
            "smoothed": ema_state["smoothed"],
            "beta": ema_state["beta"],
            "error": ema_state["error"],
            "drift": ema_state["drift"],
            "weight": weight,
            "correlation": corr,
            "severity": severity,
            "improvement": improvement,
            "error_threshold": ema_state.get("error_threshold", 0.05),
            "drift_threshold": ema_state.get("drift_threshold", 0.12),
        }


class AutonomyManager:
    """
    Autonomie de l'agent :
      - micro-constitution (principes) -> alignement doux
      - auto-seed d'objectifs √† partir de l'√©tat interne + environnement (inbox)
      - gestion d'agenda (priorit√©s, d√©duplication, fallback si vide)
      - int√©gration souple avec GoalSystem (si disponible) + logs
    """
    def __init__(self,
                 architecture,
                 goal_system=None,
                 metacognition=None,
                 memory=None,
                 perception=None,
                 language=None):

        self.arch = architecture
        self.goals = goal_system
        self.metacog = metacognition
        self.memory = memory
        self.perception = perception
        self.language = language

        # Flags / Config
        self.SELF_SEED: bool = True              # auto-g√©n√©ration par d√©faut
        self.FALLBACK_AFTER_TICKS: int = 8       # si rien d'utile √©mis ‚Üí fallback
        self.MAX_QUEUE: int = 50
        self.MIN_USEFUL_QUESTIONS: int = 1       # toujours pousser un minimum de questions utiles
        self.LAST_N_DEDUPE: int = 40             # fen√™tre de d√©duplication

        # Micro-constitution : principes (pas une todo-list)
        self.constitution: List[str] = [
            "Toujours expliciter ce qui manque (donn√©es, contraintes) avant d'agir.",
            "Optimiser le ratio progr√®s/co√ªt (temps, confusion, dette).",
            "Am√©liorer en priorit√© les capacit√©s g√©n√©rales (langage, raisonner, apprendre).",
            "Valider par boucles courtes: hypoth√®ses ‚Üí preuves/feedback.",
            "Respecter l'humain (clart√©, coop√©ration, s√©curit√©)."
        ]

        # Fallback seed (au cas o√π l'auto-seed n'√©met rien d'utile)
        self.fallback_seed: List[Dict[str, Any]] = [
            {
                "title": "Cartographier mes modules et leurs m√©triques",
                "kind": "meta",
                "priority": 0.9,
                "rationale": "Avoir une vue claire pour d√©cider quoi am√©liorer en premier.",
                "payload": {"action": "snapshot_modules"}
            },
            {
                "title": "Analyser l'inbox et cr√©er un plan d'int√©gration",
                "kind": "intake",
                "priority": 0.8,
                "rationale": "L'environnement est source de contexte et d'apprentissage.",
                "payload": {"action": "scan_inbox", "path": "./inbox"}
            },
            {
                "title": "Am√©liorer ma compr√©hension du langage (glossaire perso)",
                "kind": "learning",
                "priority": 0.75,
                "rationale": "Meilleure compr√©hension ‚Üí meilleures interactions.",
                "payload": {"action": "build_glossary", "target": "core_terms"}
            }
        ]

        # √âtat interne
        self.agenda: deque[AgendaItem] = deque(maxlen=self.MAX_QUEUE)
        self.recent_keys: deque[str] = deque(maxlen=self.LAST_N_DEDUPE)
        self.ticks_without_useful: int = 0
        self.last_tick = 0.0
        self._lock = threading.Lock()
        self.metric_states: Dict[str, MetricLearningState] = {}
        self.weight_learner = OnlineWeightLearner()

        # Journal
        self.log_dir = "./logs"
        self.log_path = os.path.join(self.log_dir, "autonomy.log")
        os.makedirs(self.log_dir, exist_ok=True)
        self._log("üîß AutonomyManager pr√™t (SELF_SEED=True, fallback activ√©)")

    # ---------- Public API ----------

    def tick(self) -> None:
        """
        Appeler √† chaque cycle (ex: dans CognitiveArchitecture.cycle()).
        - S√®me si n√©cessaire (auto-seed)
        - √âmet au moins une question utile si contexte flou
        - Ex√©cute (l√©g√®rement) certaines t√¢ches "automatiques" (scan inbox, snapshot‚Ä¶)
        - Pousse les objectifs vers GoalSystem si pr√©sent
        """
        with self._lock:
            now = time.time()
            if now - self.last_tick < 0.5:
                return  # √©vite le spam si le cycle est tr√®s rapide
            self.last_tick = now

            # 1) S√®me de nouveaux objectifs si l'agenda est pauvre
            self._maybe_seed()

            # 2) √âvite la stagnation : s'il n'y a pas d'√©l√©ment "utile", fallback
            if self._agenda_is_poor():
                self._log("‚ö†Ô∏è Agenda peu utile ‚Üí fallback seed")
                self._inject_fallback_seed()

            # 3) √âmet au moins une question utile si besoin
            self._maybe_emit_useful_question()

            # 4) Essaie de "d√©marrer" la prochaine t√¢che ex√©cutable (automatique)
            item = self._pop_next_item()
            if item:
                self._execute_item(item)

    # ---------- Seeding ----------

    def _maybe_seed(self) -> None:
        if not self.SELF_SEED:
            return
        proposals = self._auto_seed_proposals()
        added = 0
        for p in proposals:
            if self._push_if_new(p):
                added += 1
        if added:
            self._log(f"üå± Auto-seed: +{added} objectif(s)")

    def _auto_seed_proposals(self) -> List[Dict[str, Any]]:
        """
        G√©n√®re des propositions √† partir :
          - des m√©triques faibles (metacognition.performance_tracking)
          - de la pr√©sence de fichiers en inbox
          - de lacunes de langage (si language pr√©sent)
        """
        props: List[Dict[str, Any]] = []

        # a) lacunes / signaux faibles depuis la m√©tacognition
        weak = self._detect_weak_capabilities()
        for cap_state in weak:
            cap = cap_state["metric"]
            score = cap_state["smoothed"]
            props.append({
                "title": f'Am√©liorer la capacit√© "{cap}"',
                "kind": "learning",
                "priority": self._priority_from_metric(cap_state),
                "rationale": self._rationale_from_metric(cap_state),
                "payload": {"action": "improve_metric", "metric": cap}
            })

        # b) environnement (inbox)
        inbox_path = "./inbox"
        if os.path.isdir(inbox_path) and self._dir_has_content(inbox_path):
            props.append({
                "title": "Analyser l'inbox (fichiers r√©cents)",
                "kind": "intake",
                "priority": 0.8,
                "rationale": "Nouveaux indices contextuels disponibles.",
                "payload": {"action": "scan_inbox", "path": inbox_path}
            })

        # c) langage / explication - toujours utile si pas de base lexicale
        if self.language and hasattr(self.language, "known_terms"):
            if len(getattr(self.language, "known_terms", {})) < 20:
                props.append({
                    "title": "Construire un glossaire minimal",
                    "kind": "learning",
                    "priority": 0.7,
                    "rationale": "Renforcer la base s√©mantique (termes fr√©quents).",
                    "payload": {"action": "build_glossary", "target": "core_terms"}
                })
        else:
            # si module language inconnu ‚Üí t√¢che d'investigation
            props.append({
                "title": "√âvaluer mes capacit√©s de langage",
                "kind": "meta",
                "priority": 0.65,
                "rationale": "Identifier mes limites de compr√©hension/production.",
                "payload": {"action": "self_language_probe"}
            })

        # d) principe : toujours demander ce qui manque si le contexte est flou
        if self._context_is_fuzzy():
            props.append({
                "title": "Clarifier le contexte et les contraintes",
                "kind": "alignment",
                "priority": 0.85,
                "rationale": "Constitution: expliciter ce qui manque avant d'agir.",
                "payload": {"action": "ask_user", "question": self._build_clarifying_question()}
            })

        return props

    # ---------- Ex√©cution locale (l√©g√®re) ----------

    def _execute_item(self, item: AgendaItem) -> None:
        """Ex√©cute rapidement les t√¢ches simples; sinon pousse vers GoalSystem."""
        item.status = "running"
        self._log(f"‚ñ∂Ô∏è Ex√©cution: {item.title} [{item.kind}]")

        action = (item.payload or {}).get("action")

        try:
            if action == "scan_inbox":
                listed = self._list_inbox(item.payload.get("path", "./inbox"))
                self._log(f"üìÇ Inbox: {len(listed)} √©l√©ment(s) d√©tect√©(s).")
                # Ajoute sous-t√¢ches d'int√©gration
                for name in listed[:20]:
                    self._push_if_new({
                        "title": f'Int√©grer le fichier "{name}"',
                        "kind": "intake",
                        "priority": 0.6,
                        "rationale": "Transformer le contenu en connaissance exploitable.",
                        "payload": {"action": "ingest_file", "filename": name}
                    })

            elif action == "snapshot_modules":
                snap = self._snapshot_modules()
                self._write_json("./logs/autonomy_snapshot.json", snap)
                self._log("üß≠ Snapshot des modules √©crit dans logs/autonomy_snapshot.json")

            elif action == "build_glossary":
                # On ne modifie pas le code du module langage; on pr√©pare juste une todo structur√©e.
                terms = self._propose_core_terms()
                self._write_json("./logs/proposed_glossary.json", {"terms": terms})
                self._log("üóÇÔ∏è Glossaire propos√© dans logs/proposed_glossary.json")

            elif action == "self_language_probe":
                report = self._language_probe()
                self._write_json("./logs/language_probe.json", report)
                self._log("üîé Rapport de sonde langage dans logs/language_probe.json")

            elif action == "ask_user":
                q = item.payload.get("question") or "De quoi as-tu besoin que je fasse en priorit√© ?"
                print(f"\nü§î (Autonomy) Question: {q}\n")
                # rien d'autre √† faire; la r√©ponse utilisateur alimente la suite

            else:
                # Si ce n'est pas une t√¢che locale ‚Üí pousser vers GoalSystem si dispo
                self._push_to_goal_system(item)

        except Exception as e:
            self._log(f"‚ùå Erreur ex√©cution t√¢che: {e}")

        item.status = "done"

    def _push_to_goal_system(self, item: AgendaItem) -> None:
        if not self.goals:
            return
        # on tente des API communes sans casser si absentes
        pushed = False
        try:
            if hasattr(self.goals, "add_goal"):
                self.goals.add_goal({
                    "id": item.id,
                    "title": item.title,
                    "rationale": item.rationale,
                    "kind": item.kind,
                    "priority": item.priority,
                    "payload": item.payload
                })
                pushed = True
            elif hasattr(self.goals, "register_goal"):
                self.goals.register_goal(item.title, item.payload)
                pushed = True
        except Exception as e:
            self._log(f"‚ö†Ô∏è GoalSystem indisponible: {e}")

        if pushed:
            self._log(f"üìå Objectif pouss√© vers GoalSystem: {item.title}")

    # ---------- Utilitaires d'agenda ----------

    def _push_if_new(self, p: Dict[str, Any]) -> bool:
        """Ajoute un item si pas de doublon r√©cent (dedupe_key)."""
        dedupe_key = p.get("dedupe_key") or f"{p.get('kind')}::{p.get('title')}"
        if dedupe_key in self.recent_keys:
            return False

        itm = AgendaItem(
            id=str(uuid.uuid4()),
            title=p["title"],
            rationale=p.get("rationale", ""),
            kind=p.get("kind", "meta"),
            priority=float(p.get("priority", 0.5)),
            created_at=time.time(),
            payload=p.get("payload", {}),
            status="queued",
            dedupe_key=dedupe_key
        )
        self.agenda.append(itm)
        self.recent_keys.append(dedupe_key)
        return True

    def _pop_next_item(self) -> Optional[AgendaItem]:
        if not self.agenda:
            return None
        # priorit√© simple (max priority, plus ancien en cas d'√©galit√©)
        best_idx = None
        best_score = -1.0
        for i, itm in enumerate(self.agenda):
            score = itm.priority - (0.02 * ((time.time() - itm.created_at) / 10.0))
            if score > best_score:
                best_score = score
                best_idx = i
        if best_idx is None:
            return None
        best_item = self.agenda[best_idx]
        del self.agenda[best_idx]
        return best_item

    def _agenda_is_poor(self) -> bool:
        """Heuristique: pas d'items 'intake'/'learning'/'alignment' √† priorit√© >= 0.6"""
        useful = [i for i in self.agenda if i.kind in ("intake", "learning", "alignment") and i.priority >= 0.6]
        if not useful:
            self.ticks_without_useful += 1
        else:
            self.ticks_without_useful = 0
        return self.ticks_without_useful >= self.FALLBACK_AFTER_TICKS

    def _inject_fallback_seed(self) -> None:
        for p in self.fallback_seed:
            self._push_if_new(p)
        self.ticks_without_useful = 0

    # ---------- Capteurs/√©tat ----------

    def _detect_weak_capabilities(self) -> List[Dict[str, float]]:
        """Retourne les m√©triques faibles avec lissage adaptatif et poids dynamiques."""
        res: List[Dict[str, float]] = []
        try:
            perf = (self.metacog.cognitive_monitoring.get("performance_tracking", {})
                    if self.metacog else {})
            # on lit la derni√®re valeur si dispo
            for metric, data in perf.items():
                if not data:
                    continue
                val = data[-1]["value"] if isinstance(data, list) and data else 0.0
                if metric not in self.metric_states:
                    self.metric_states[metric] = MetricLearningState(metric)
                state = self.metric_states[metric].observe(float(val), self.weight_learner)
                if state["smoothed"] < 0.7:
                    res.append(state)
                    self._maybe_log_metric_events(state)
        except Exception:
            pass
        res.sort(key=lambda s: (s["smoothed"], -s["weight"]))
        return res[:5]

    def _priority_from_metric(self, state: Dict[str, float]) -> float:
        base = 0.55 + (0.25 * state["weight"])
        severity = min(0.45, state["severity"] * 0.45)
        priority = min(0.98, base + severity)
        return priority

    def _rationale_from_metric(self, state: Dict[str, float]) -> str:
        metric = state["metric"]
        smoothed = state["smoothed"]
        beta = state["beta"]
        correlation = state["correlation"]
        return (
            f'La m√©trique "{metric}" est liss√©e √† {smoothed:.2f} '
            f'(Œ≤ adaptatif={beta:.2f}, corr={correlation:.2f}).'
        )

    def _maybe_log_metric_events(self, state: Dict[str, float]) -> None:
        drift = state.get("drift", 0.0)
        error = state.get("error", 0.0)
        corr = state.get("correlation", 0.0)
        metric = state["metric"]
        drift_threshold = state.get("drift_threshold", 0.12)
        error_threshold = state.get("error_threshold", 0.2)
        if drift > drift_threshold:
            self._log(f"üìà Drift d√©tect√© sur {metric} (Œî={drift:.3f})")
        if error > error_threshold:
            self._log(f"üìâ Signal bruit√© pour {metric} (erreur={error:.3f})")
        prev_corr = getattr(self.metric_states[metric], "last_corr", 0.0)
        if abs(corr - prev_corr) > 0.05:
            trend = "‚Üë" if corr > prev_corr else "‚Üì"
            self._log(f"üîÅ Corr√©lation {trend} pour {metric}: {prev_corr:.2f} ‚Üí {corr:.2f}")
            self.metric_states[metric].last_corr = corr

    def _context_is_fuzzy(self) -> bool:
        """V√©rifie s'il y a assez d'infos pour agir sans demander √† l'utilisateur."""
        # Simple heuristique : pas de fichiers, pas de t√¢ches intake >= 0.6, pas de user_msg r√©cent (non accessible ici)
        has_intake = any(i for i in self.agenda if i.kind == "intake" and i.priority >= 0.6)
        return (not has_intake) and (not self._dir_has_content("./inbox"))

    def _maybe_emit_useful_question(self) -> None:
        questions = [i for i in self.agenda if i.kind == "alignment" and i.status == "queued"]
        if len(questions) >= self.MIN_USEFUL_QUESTIONS:
            return
        # Injecte une question courte et utile
        self._push_if_new({
            "title": "Question de clarification (priorit√©s & contexte)",
            "kind": "alignment",
            "priority": 0.8,
            "rationale": "R√©duire l'incertitude avant d'allouer des efforts.",
            "payload": {
                "action": "ask_user",
                "question": self._build_clarifying_question()
            }
        })

    # ---------- Actions concr√®tes ----------

    def _list_inbox(self, path: str) -> List[str]:
        try:
            return [f for f in os.listdir(path) if not f.startswith(".")]
        except Exception:
            return []

    def _snapshot_modules(self) -> Dict[str, Any]:
        snap = {"time": time.time(), "modules": {}, "constitution": self.constitution}
        for name in ("memory", "perception", "reasoning", "goals", "metacognition", "creativity", "world_model", "language"):
            obj = getattr(self.arch, name, None)
            snap["modules"][name] = {
                "present": obj is not None and not isinstance(obj, str),
                "attrs": sorted([a for a in dir(obj)])[:30] if obj else []
            }
        return snap

    def _propose_core_terms(self) -> List[str]:
        return [
            "objectif", "priorit√©", "rationale", "contexte",
            "contrainte", "hypoth√®se", "preuve", "feedback",
            "incertitude", "co√ªt", "b√©n√©fice", "it√©ration"
        ]

    def _language_probe(self) -> Dict[str, Any]:
        report = {
            "can_parse": bool(self.language and hasattr(self.language, "parse_utterance")),
            "has_vocab": bool(self.language and hasattr(self.language, "known_terms")),
            "notes": []
        }
        if not report["can_parse"]:
            report["notes"].append("parse_utterance indisponible ‚Üí clarifier l'API du module langage.")
        if not report["has_vocab"]:
            report["notes"].append("Pas de vocabulaire interne d√©tect√© ‚Üí construire un glossaire initial.")
        return report

    # ---------- Helpers ----------

    def _build_clarifying_question(self) -> str:
        base = [
            "Quel est l'objectif le plus important pour toi maintenant ?",
            "Y a-t-il des contraintes (temps, format, sources) que je dois respecter ?",
            "Souhaites-tu que je priorise l'exploration ou la fiabilit√© ?"
        ]
        return " / ".join(base)

    def _dir_has_content(self, path: str) -> bool:
        try:
            return any(not f.startswith(".") for f in os.listdir(path))
        except Exception:
            return False

    def _write_json(self, path: str, data: Dict[str, Any]) -> None:
        try:
            with open(path, "w", encoding="utf-8") as f:
                json.dump(json_sanitize(data), f, ensure_ascii=False, indent=2)
        except Exception as e:
            self._log(f"‚ö†Ô∏è √âchec d'√©criture JSON {path}: {e}")

    def _log(self, msg: str) -> None:
        stamp = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
        line = f"[{stamp}] {msg}"
        try:
            with open(self.log_path, "a", encoding="utf-8") as f:
                f.write(line + "\n")
        except Exception:
            pass
        # echo console minimal
        print(f"[Autonomy] {msg}")

"""Autonomy related helpers."""

from .core import AutonomyCore

__all__ = ["AutonomyCore"]
