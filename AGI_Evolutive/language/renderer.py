from __future__ import annotations

from dataclasses import asdict
from typing import Dict, Any, List, Tuple, Optional

import random
import re
import time

from AGI_Evolutive.social.tactic_selector import TacticSelector
from AGI_Evolutive.social.interaction_rule import ContextBuilder
from AGI_Evolutive.core.structures.mai import MAI

from .nlg import NLGContext, apply_mai_bids_to_nlg, paraphrase_light, join_tokens
from .style_critic import StyleCritic


def _tokens(s: str) -> set:
    return set(re.findall(r"[A-Za-zÃ€-Ã¿]{3,}", (s or "").lower()))


def _build_language_state_snapshot(arch, ctx: Dict[str, Any]) -> Dict[str, Any]:
    dialogue_ctx = ctx.get("dialogue") or ctx.get("dialogue_state")
    if dialogue_ctx is None:
        dialogue_ctx = getattr(getattr(arch, "language", None), "state", None)
    return {
        "beliefs": getattr(arch, "beliefs", None),
        "self_model": getattr(arch, "self_model", None),
        "dialogue": dialogue_ctx,
        "world": getattr(arch, "world_model", None),
    }


def _apply_action_hint(text: str, hint: str) -> str:
    hint = (hint or "").strip()
    lower = text.lower()
    if hint == "AskConsent":
        prefix = "Avant de poursuivre, pourrais-tu confirmer que je peux partager ces informations ? "
        if not lower.startswith(prefix.lower()):
            return prefix + text
    elif hint == "RefusePolitely":
        apology = "Je suis dÃ©solÃ©, je ne peux pas partager cette information."
        if apology.lower() not in lower:
            return f"{apology} {text}".strip()
    elif hint == "PartialReveal":
        note = "(Je partage uniquement ce qui est appropriÃ© pour protÃ©ger la confidentialitÃ©.)"
        if note.lower() not in lower:
            return f"{text}\n\n{note}"
    elif hint == "RephraseRespectfully":
        marker = "Je vais reformuler avec plus de dÃ©licatesse :"
        if marker.lower() not in lower:
            return f"{marker} {text}"
    return text


class LanguageRenderer:
    def __init__(self, voice_profile, lexicon, ranker=None):
        self.voice = voice_profile
        self.lex = lexicon
        self.ranker = ranker
        # anti-spam / frÃ©quence
        self._cooldown = {"past": 0.0, "colloc": 0.0}
        self._last_used = {"past": "", "colloc": ""}

        # seuils rÃ©glables
        self.THRESH = {
            "past_relevance": 0.25,   # pertinence mini lien passÃ©
            "colloc_relevance": 0.20, # pertinence mini collocation
            "conf_min": 0.55,         # confiance mini pour ornement
            "chance_colloc": 0.35,    # proba de tenter une collocation (modulÃ©e)
            "quote_prob": 0.35,
        }

        self.critic = StyleCritic(max_chars=1200)
        self._rand = random.Random()

    def rand(self) -> float:
        return self._rand.random()

    # ---------- utilitaires ----------
    def apply_action_hint(self, text: str, hint: str) -> str:
        """Expose l'utilitaire d'application d'hints MAI pour d'autres pipelines."""

        return _apply_action_hint(text, hint)

    def _confidence(self) -> float:
        # essaie dâ€™extraire une confiance globale depuis la policy
        try:
            pol = self.voice.self_model.arch.policy
            if hasattr(pol, "confidence"):
                return float(pol.confidence())
        except Exception:
            pass
        return 0.6

    def _budget_chars(self, ctx: Dict[str, Any]) -> int:
        # budget dâ€™ornement selon style utilisateur / voix
        st = self.voice.style()
        user = (ctx.get("user_style") or {})
        base = 160  # budget max dâ€™ornement
        if user.get("prefers_long"):
            base += 80
        if st.get("conciseness", 0.6) > 0.7:
            base -= 60
        return max(0, base)

    def _decrease_cooldowns(self, store: Optional[Dict[str, float]] = None) -> None:
        # refroidit un peu Ã  chaque appel
        target = store if store is not None else self._cooldown
        for k in target:
            target[k] = max(0.0, target[k] - 0.34)

    # ---------- sÃ©lection â€œlien au passÃ©â€ ----------
    def _pick_relevant_moment(self, user_msg: str, ctx: Dict[str, Any]) -> Tuple[str, float]:
        moments: List[str] = ctx.get("key_moments") or []
        if not moments:
            return ("", 0.0)
        utoks = _tokens(user_msg)
        best, score = "", 0.0
        for m in moments[-8:]:
            mtoks = _tokens(m)
            if not mtoks:
                continue
            jacc = len(utoks & mtoks) / max(1, len(utoks | mtoks))
            if jacc > score:
                best, score = m, jacc
        return (best, score)

    # ---------- sÃ©lection â€œcollocation aimÃ©eâ€ ----------
    def _pick_collocation(self, ctx: Dict[str, Any]) -> Tuple[str, float]:
        topics = set(ctx.get("topics") or [])
        cand = self.lex.sample_collocation(novelty=0.3)
        if not cand:
            return ("", 0.0)
        rel = len(_tokens(cand) & topics) / max(1, len(_tokens(cand)))
        return (cand, rel)

    # ---------- dÃ©cor et rendu ----------
    def _decorate_with_voice(self, text: str) -> str:
        st = self.voice.style()
        if st.get("formality", 0.4) > 0.75 and not text.lower().startswith(("bonjour", "bonsoir")):
            text = "Bonjour, " + text
        if st.get("warmth", 0.6) > 0.75 and not text.endswith("!"):
            text += " (je reste dispo si besoin)"
        if st.get("emoji", 0.2) > 0.6:
            text = "ðŸ™‚ " + text
        return text

    def render_reply(self, semantics: Dict[str, Any], ctx: Dict[str, Any], *, dry_run: bool = False) -> str:
        """
        RÃ¨gle : on nâ€™ajoute un lien au passÃ© / une collocation QUE si :
        - confiance >= conf_min
        - pertinence >= seuils
        - budget > 0
        - cooldown OK et pas de doublon
        Et au plus 1 ornement par rÃ©ponse (prioritÃ© au lien passÃ©).
        """
        ctx = ctx or {}
        if dry_run:
            ctx = dict(ctx)

        cooldown = dict(self._cooldown)
        last_used = dict(self._last_used)

        self._decrease_cooldowns(cooldown)
        base = (semantics.get("text") or "").strip() or "Je te rÃ©ponds en tenant compte de notre historique."
        arch = getattr(getattr(self.voice, "self_model", None), "arch", None)
        policy = getattr(arch, "policy", None) if arch else None
        state_snapshot: Dict[str, Any] = {}
        predicate_registry: Dict[str, Any] = {}
        applicable_mais: List[MAI] = []
        if arch and policy and hasattr(policy, "build_predicate_registry"):
            try:
                state_snapshot = ctx.get("state_snapshot") or _build_language_state_snapshot(arch, ctx)
                predicate_registry = policy.build_predicate_registry(state_snapshot)
            except Exception:
                state_snapshot = {}
                predicate_registry = {}

        nlg_context = NLGContext(base, _apply_action_hint)
        try:
            applicable_mais = apply_mai_bids_to_nlg(nlg_context, state_snapshot, predicate_registry)
        except Exception:
            applicable_mais = []
        base = nlg_context.text
        applied_hints = nlg_context.applied_hints()
        if applied_hints and not dry_run:
            ctx.setdefault("applied_action_hints", []).extend(applied_hints)
        conf = self._confidence()
        budget = self._budget_chars(ctx)

        # Si la question est directe / lâ€™utilisateur veut court â†’ pas dâ€™ornement
        is_direct_question = "?" in (ctx.get("last_message") or "")
        if conf < self.THRESH["conf_min"] or budget < 60 or (ctx.get("user_style") or {}).get("prefers_long") is False:
            return self._decorate_with_voice(base)

        # 1) Candidat lien au passÃ©
        past_txt, past_rel = self._pick_relevant_moment(ctx.get("last_message", ""), ctx)
        use_past = (
            past_txt
            and past_rel >= self.THRESH["past_relevance"]
            and cooldown["past"] <= 0.0
            and past_txt != last_used["past"]
            and not is_direct_question  # on Ã©vite de dÃ©tourner une question courte
        )

        # 2) Candidat collocation aimÃ©e (faible proba, modulÃ©e par confiance)
        colloc_txt, colloc_rel = self._pick_collocation(ctx)
        p_try = self.THRESH["chance_colloc"] * (0.6 + 0.6 * conf)
        use_colloc = (
            colloc_txt
            and random.random() < p_try
            and colloc_rel >= self.THRESH["colloc_relevance"]
            and cooldown["colloc"] <= 0.0
            and colloc_txt != last_used["colloc"]
        )

        # Toujours max 1 ornement, prioritÃ© au passÃ© sâ€™il est pertinent
        if arch and getattr(arch, "memory", None):
            try:
                arch.tactic_selector = getattr(arch, "tactic_selector", TacticSelector(arch))
                selector_ctx = ContextBuilder.build(
                    arch,
                    extra={
                        "pending_questions_count": len(
                            getattr(getattr(arch, "question_manager", None), "pending_questions", [])
                            or []
                        )
                    },
                )
                rule, why = arch.tactic_selector.pick(selector_ctx)
            except Exception:
                rule, why = (None, None)
            if rule:
                if not dry_run:
                    rule["last_used_ts"] = time.time()
                    rule["usage_count"] = int(rule.get("usage_count", 0)) + 1
                    if hasattr(arch.memory, "update_memory"):
                        arch.memory.update_memory(rule)
                    else:
                        arch.memory.add_memory(rule)

                    arch.memory.add_memory(
                        {
                            "kind": "decision_trace",
                            "rule_id": rule["id"],
                            "tactic": (rule.get("tactic") or {}).get("name"),
                            "ctx_snapshot": selector_ctx,
                            "why": why,
                            "ts": time.time(),
                        }
                    )

                tac = (rule.get("tactic") or {}).get("name", "")
                if tac == "banter_leger" and "?" not in base:
                    base = base + " (clin dâ€™Å“il)"
                elif tac == "ack_grateful":
                    base = base + " Merci, je le note."
                elif tac == "reformulation_empathique":
                    params = (rule.get("tactic") or {}).get("params") or {}
                    try:
                        ratio = float(params.get("mirror_ratio", 0.5))
                    except Exception:
                        ratio = 0.5
                    ratio = max(0.1, min(0.9, ratio))
                    user_msg = str(ctx.get("last_message") or "")
                    snippet = ""
                    if user_msg:
                        tokens = re.findall(r"[A-Za-zÃ€-Ã¿'â€™]+", user_msg)
                        if tokens:
                            take = max(3, int(len(tokens) * ratio))
                            snippet = join_tokens(tokens[:take])
                            if len(snippet) > 120:
                                snippet = snippet[:117].rstrip() + "â€¦"
                    if snippet:
                        empathy = f"Si je comprends bien, tu parles de Â« {snippet} Â»."
                    else:
                        empathy = "Si je comprends bien, ce sujet te tient Ã  cÅ“ur."
                    if empathy.lower() not in base.lower():
                        base = f"{empathy} {base}".strip()
                elif tac == "clarify_definition":
                    params = (rule.get("tactic") or {}).get("params") or {}
                    ensure_example = bool(params.get("ensure_example"))
                    state_snapshot = ctx.get("state_snapshot") or {}
                    dialogue_state = state_snapshot.get("dialogue") if isinstance(state_snapshot, dict) else None

                    def _iter_unknown_terms(dialogue: Any):
                        if dialogue is None:
                            return
                        if isinstance(dialogue, dict):
                            frames = dialogue.get("recent_frames", []) or []
                            for frame in reversed(frames):
                                if not isinstance(frame, dict):
                                    continue
                                for key in ("unknown_terms", "terms_need_definition", "unknowns"):
                                    vals = frame.get(key) or []
                                    for val in vals:
                                        if val:
                                            yield str(val)
                            profile = dialogue.get("user_profile", {})
                            if isinstance(profile, dict):
                                for val in reversed(profile.get("unknown_terms", []) or []):
                                    if val:
                                        yield str(val)
                            return
                        frames = list(getattr(dialogue, "recent_frames", []) or [])
                        for frame in reversed(frames):
                            if isinstance(frame, dict):
                                sources = [
                                    frame.get("unknown_terms"),
                                    frame.get("terms_need_definition"),
                                    frame.get("unknowns"),
                                ]
                            else:
                                sources = [
                                    getattr(frame, "unknown_terms", None),
                                    getattr(frame, "terms_need_definition", None),
                                    getattr(frame, "unknowns", None),
                                ]
                            for vals in sources:
                                if not vals:
                                    continue
                                for val in vals:
                                    if val:
                                        yield str(val)
                        profile = getattr(dialogue, "user_profile", None)
                        if isinstance(profile, dict):
                            for val in reversed(profile.get("unknown_terms", []) or []):
                                if val:
                                    yield str(val)

                    term = None
                    for candidate in _iter_unknown_terms(dialogue_state):
                        candidate = candidate.strip()
                        if candidate:
                            term = candidate
                            break
                    if term is None:
                        topics = ctx.get("topics") or []
                        if topics:
                            term = str(topics[0]).strip()
                    if term:
                        intro = f"Pour clarifier, quand je parle de Â« {term} Â», j'entends ceci :"
                        if intro.lower() not in base.lower():
                            base = f"{intro} {base}".strip()
                    if ensure_example and "exemple" not in base.lower():
                        last_msg = str(ctx.get("last_message") or "")
                        example_snippet = ""
                        if last_msg:
                            tokens = re.findall(r"[A-Za-zÃ€-Ã¿'â€™]+", last_msg)
                            if tokens:
                                limit = min(len(tokens), 12)
                                example_snippet = join_tokens(tokens[:limit])
                                if len(example_snippet) > 80:
                                    example_snippet = example_snippet[:77].rstrip() + "â€¦"
                        if example_snippet:
                            base += (
                                f" Par exemple, dans ce que tu viens d'Ã©voquer (Â« {example_snippet} Â»),"
                                " cette dÃ©finition s'applique."
                            )
                        else:
                            base += " Par exemple, on peut penser Ã  une situation concrÃ¨te pour l'illustrer."

        out = self._decorate_with_voice(base)
        if use_past:
            snippet = f"\n\nâ†ª En lien : {past_txt}"
            if len(snippet) <= budget:
                out += snippet
                cooldown["past"] = 2.0
                last_used["past"] = past_txt
                if not dry_run:
                    self._cooldown = cooldown
                    self._last_used = last_used
                return out  # on sâ€™arrÃªte ici

        if use_colloc:
            snippet = f"\n\n({colloc_txt})"
            if len(snippet) <= budget:
                out += snippet
                cooldown["colloc"] = 2.0
                last_used["colloc"] = colloc_txt
                if not dry_run:
                    self._cooldown = cooldown
                    self._last_used = last_used

        if not dry_run and ctx.get("omitted_content") and arch:
            payload = {
                "reason": "MAI-driven",
                "mai_ids": [mai.id for mai in applicable_mais],
                "evidence": [
                    asdict(doc)
                    for mai in applicable_mais
                    for doc in getattr(mai, "provenance_docs", [])
                ],
            }
            audit = getattr(arch, "audit", None)
            if audit and hasattr(audit, "log_omission_justifiee"):
                try:
                    audit.log_omission_justifiee(**payload)
                except Exception:
                    pass
            else:
                logger = getattr(arch, "logger", None)
                if logger and hasattr(logger, "write"):
                    try:
                        logger.write("nlg.omission", **payload)
                    except Exception:
                        pass

        if not dry_run:
            self._cooldown = cooldown
            self._last_used = last_used
        return out

    # --- GÃ©nÃ¨re K variantes (macros + paraphrases lÃ©gÃ¨res) ---
    def render_reply_candidates(self, ctx: Dict[str, Any], base_plan: Dict[str, Any], K: int = 4) -> List[str]:
        plan = dict(base_plan or {})
        ctx = dict(ctx or {})

        neutral = self._render_once(ctx, plan, macro=None)
        candidates: List[str] = [neutral]

        macros = ["taquin", "coach", "sobre", "deadpan"]
        self._rand.shuffle(macros)
        for macro in macros:
            if len(candidates) >= max(1, K):
                break
            variant = self._render_once(ctx, plan, macro=macro)
            if variant and variant not in candidates:
                candidates.append(variant)

        out: List[str] = []
        for i, cand in enumerate(candidates):
            if i == 0:
                out.append(cand)
            else:
                out.append(paraphrase_light(cand, prob=0.30))
        return out[: max(1, K)]

    def _render_once(self, ctx: Dict[str, Any], plan: Dict[str, Any], macro: Optional[str] = None) -> str:
        sp = getattr(self.voice, "style_policy", None)
        snapshot = None
        mode_snapshot = None
        macro = (macro or "").lower() or None
        if sp and macro and hasattr(sp, "apply_macro"):
            try:
                snapshot = dict(getattr(sp, "params", {}))
                mode_snapshot = getattr(sp, "current_mode", None)
                sp.apply_macro(macro)
            except Exception:
                snapshot = None
                mode_snapshot = None

        try:
            text = self.render_reply(plan, ctx, dry_run=True)
        finally:
            if sp and snapshot is not None:
                try:
                    sp.params.update(snapshot)
                    if mode_snapshot is not None:
                        sp.current_mode = mode_snapshot
                except Exception:
                    pass

        macro_text = text
        if macro:
            if macro == "taquin" and "ðŸ˜‰" not in macro_text:
                macro_text = macro_text.strip() + " ðŸ˜‰"
            elif macro == "coach":
                prefix = "Coach mode â–¶ "
                if not macro_text.lower().startswith(prefix.lower()):
                    macro_text = f"{prefix}{macro_text}" if macro_text else prefix.rstrip()
            elif macro == "sobre":
                macro_text = re.sub(r"[ðŸ™‚ðŸ˜‰ðŸ˜Š]+\s*", "", macro_text).strip()
            elif macro == "deadpan":
                lines: List[str] = []
                for line in macro_text.splitlines():
                    normalized = line.replace("!", ".").replace("â€¦", ".")
                    tokens = normalized.split()
                    lines.append(join_tokens(tokens))
                macro_text = "\n".join(lines).strip()

        return macro_text.strip()

    def render_final(self, ctx: Dict[str, Any], plan: Dict[str, Any]) -> Dict[str, Any]:
        ctx_local = dict(ctx or {})
        plan_local = dict(plan or {})
        candidates = self.render_reply_candidates(ctx_local, plan_local, K=4)

        local_ctx = {
            "style": dict(getattr(getattr(self.voice, "style_policy", None), "params", {}))
        }
        scored: List[Tuple[float, int, str]] = []
        for idx, candidate in enumerate(candidates):
            try:
                score = (
                    float(self.ranker.score(local_ctx, candidate))
                    if self.ranker is not None
                    else 0.5
                )
            except Exception:
                score = 0.5
            scored.append((score, idx, candidate))

        if not scored:
            return {"text": "", "chosen": None, "alts": []}

        scored.sort(key=lambda x: x[0], reverse=True)
        best_score, chosen_idx, best_text = scored[0]

        analysis = self.critic.analyze(best_text)
        rewritten = self.critic.rewrite(best_text)
        best_text = rewritten

        final_text, quote_meta = self._maybe_add_quote(best_text, ctx_local)

        return {
            "text": final_text,
            "chosen": {
                "idx": chosen_idx,
                "score": best_score,
                "text": final_text,
                "analysis": analysis,
                "quote": quote_meta,
            },
            "alts": [
                {"idx": idx, "score": score, "text": text}
                for score, idx, text in scored[1:]
            ],
        }

    def _ctx_is_safe_for_aside(self, ctx: Dict[str, Any]) -> bool:
        user_msg = (ctx.get("last_user_msg") or ctx.get("last_message") or "").lower()
        for bad in ["dÃ©cÃ¨s", "urgence", "mauvaise nouvelle", "licenciement", "plainte"]:
            if bad in user_msg:
                return False
        return True

    def _maybe_add_quote(self, text: str, ctx: Dict[str, Any]):
        quote_meta = None
        qm = getattr(self.voice, "quote_memory", None) or getattr(self, "quote_memory", None)
        if not qm:
            return text, quote_meta
        if (
            len(text) < 900
            and self._ctx_is_safe_for_aside(ctx)
            and self.rand() < self.THRESH["quote_prob"]
        ):
            try:
                context_seed = text + " " + (ctx.get("last_user_msg") or "")
                quote = qm.sample(context=context_seed)
            except Exception:
                quote = None
            if quote:
                quote_used = quote
                if len(quote.split()) > 20:
                    quote_used = paraphrase_light(quote, prob=0.45)
                text = f"{text}\n\n(Clin dâ€™Å“il) {quote_used}".strip()
                quote_meta = {"len": len(quote_used), "raw_len": len(quote)}
        return text, quote_meta
